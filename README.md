# heart_disease

## Introduction: 
Heart Disease is one of the leading causes of death but it can be detected early through various measurements and thus be prevented through early action. This problem is interesting because by running models to understand possible correlations between features and some form of heart disease, we can analyze possible avenues of early testing for patients to predict their risk for such diseases. My approach was to see any interesting visual or immediate correlations between certain features and the target value then to run models like Decision Tree, Logistic Regression, Random Forest Classifier, and Naive Bayes to compare accuracy and feature importances.

## Setup:
The Heart Disease dataset from UCI is a multivariate type that contains 14 attributes: age, sex, chest pain type, resting blood pressure, serum cholesterol, fasting blood sugar, resting electrocardiographic results, maximum heart rate achieved, exercise induced angina, oldpeak â€” ST depression induced by exercise relative to rest, the slope of the peak exercise ST segment, number of major vessels and Thalassemia. There were originally 76 features but published studies only refer to these 14 to be useful. The dataset was sourced from various hospitals like from Cleveland (main source), Hungary, Switzerland, and VA Long Beach though the last three have a lot of missing values and are thus not included in the main dataset. The data needed a bit of work because some features were catagorical so I used one-hot encoding to resolve some of the attributes like chest pain and angina. I will use Decision Tree Regression because past papers and research have shown that using such with 10 fold cross validation has been successful with this dataset and other related ones because of their ability to factor in all features and calculate probabilities within them, giving us a good idea of the problem. I will test various values for the hyper-parameters like tree-depth through trial and error and settle for the best performance among the metrics. From there, I test the other various mentioned models that I believe might do better simply because I see possible linear dependance between features from looking at the data and niche cases that models have proven to be effective in the bioinformatics field.

## Results:
From the base model of the Decision Tree Regressor, we see an accuracy of 75.41% and the main attributes it found useful were cp (chest pain), exang (exercise induced angina), trestbps (resting blood pressure), age, chol (cholesterol), and oldpeak (ST depression induced by exercise relative to rest). Through tuning the hyperparameters of the same model, we got an improvement of accuracy to 75.41% with the same features being noted as important for decision making. Through logistic regression with cross validation of 10 folds, I got an accuracy of 80.33%.

The Linear Regression model got an accuracy of 78.68% and using 10 cross fold validation, I was able to bump it up to 80.33%

The Random Forest Classifier base model got an accuracy of 78.68% and found similar features important to what the Decision Tree was able to deduce. I repeated the trials for testing specific hyper-parameter values such as max_depth, min_samples_split, and min_samples_leaf, getting values max_depth=1, min_samples_split=3, min_samples_leaf=6 that best tuned the model. With all such considered, the accuracy of the tuned Random Forest Classifier was a 81.96%. There was an option to enable Bootstrapping which I tested out of curiousity but found a small decrease in quality to 80.33% accuracy.

I decided to try out Naive Bayes because to me, it felt like I was dealing with a relatively small training set so NB is well known to handle these sorts of issues. However, running it using a Gaussian version, I saw an accuracy of 77.05%.

This problem of working with a small dataset made me think of how biased it was since it's using data from a specific Cleveland hospital. I decided to combine the datasets provided but not recommended for use. Reason being is because they had a lot of missing values which I used the mean values of our observed values (from the cleveland dataset) to fill. Ran all mentioned models and saw a significant, yet expected, dip in accuracy.

## Discussion:
As mentioned in results, though I expected a better accuracy from models like the Decision Tree Classifier, the Logistic Regression Model suprised me with an accuracy of 80.33%. The Random Forest Classifier got the highest accuracy with its hyper-parameters tuned. However, I found its max_depth to be 1 very suspicious since it's quite low but after substituting it for a value where I saw a similar but  slightly lower performance, I saw a dip in accuracy so I opted in keeping it. I don't have a good reason for the model to underfit with such a low max depth value yet do good with new data but I believe that it could be that there's a clear variable that highly indicates heart disease more than others. I believe that one-hot encoding the categorial features helped out a lot in making a model that made sense because observing others that decided not to, I suspect that their LR accuracy rates were poorer because their models had emphasis in the wrong features like chest pain. The Matrix Compeleted dataset did terrible with the same models used as metrics and I believe that using the mean values were plain wrong. I think what I could've done differently is use kNN to best match missing values to samples of similar known values (especially in the target value). Interestingly enough, the logistic regression model using the Matrix Compeleted dataset did the best of the bunch with an accuracy of 61.20% and MSE of 1.09 which does push me to believe that LR does extremely well with this dataset. I realized that others in the Kaggle community complained about the sloppiness and incorrectness of the documentation so that might possibly affect our understanding of the results.

## Conclusion:
The Heart Disease dataset from UCI came in both cleaned and raw forms, both of which I used to evaluate across out-of-the-box methods to gain insight of the features. The problem at hand is using features that involve patient age to heartbeat levels to predict whether they have any heart disease in any form (which is partly genetic but is also heavily influenced through life habits). Through testing and tuning hyper-parameters of various models, we saw that the Random Forest Classifier and the Logistic Regression Model did the best with above 80% accuracy. We combined the raw datasets sourced from other hospitals via matrix completetion with mean values for the many unknown values that they had and saw an expected dip in performance across all models. We understand that using mean values as a substitute is not the best and looking forward, kNN might be appropiate in deciding what values should samples have based off similar samples. Overall, we found that the chest pain, exercise induced angina, and number of major vessels features to be important values to consider when predicting heart disease.

## References:
https://archive.ics.uci.edu/ml/datasets/Heart+Disease
https://github.com/smarthardik10/Heart-Disease-UCI-Diagnosis-Prediction
https://www.analyticsvidhya.com/blog/2022/03/logistic-regression-on-uci-dataset/